<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MediaPipe Hand Tracking (GitHub Version!)</title>
    <script defer src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <style>
        body { text-align: center; font-family: Arial, sans-serif; }
        video { border: 2px solid black; width: 60%; }
        canvas { position: absolute; left: 50%; transform: translateX(-50%); }
        #message { font-size: 24px; font-weight: bold; margin-top: 10px; }
    </style>
</head>
<body>
    <h2>Hand Gesture Detector âœ‹ (Pure MediaPipe DIY!)</h2>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <p id="message">Show your hand!</p>

    <script>
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        const message = document.getElementById("message");

        async function startMediaPipe() {
            const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
            hands.setOptions({
                maxNumHands: 1,
                modelComplexity: 1,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });

            hands.onResults(results => {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                if (results.multiHandLandmarks) {
                    for (const landmarks of results.multiHandLandmarks) {
                        for (let i = 0; i < landmarks.length; i++) {
                            const x = landmarks[i].x * canvas.width;
                            const y = landmarks[i].y * canvas.height;
                            ctx.beginPath();
                            ctx.arc(x, y, 5, 0, 2 * Math.PI);
                            ctx.fillStyle = "red";
                            ctx.fill();
                        }
                    }
                }
            });

            const camera = new Camera(video, {
                onFrame: async () => { await hands.send({image: video}); },
                width: 640,
                height: 480
            });
            camera.start();
        }

        navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
            video.srcObject = stream;
            startMediaPipe();
        }).catch(err => console.error("Camera access error:", err));
    </script>
</body>
</html>
